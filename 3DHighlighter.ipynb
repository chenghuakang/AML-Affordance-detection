{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Liu-Yonghu/3DHighlighter/blob/main/3DHighlighter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Boot the colab"
      ],
      "metadata": {
        "id": "AWggbpuWCUle"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPi-fh_tCBh3",
        "outputId": "f8c19c43-0305-4781-a489-d6e2c39072ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xnvMupHUD0G-"
      },
      "outputs": [],
      "source": [
        "!cp -r ./drive/MyDrive/data/full_shape_val_data.pkl ./data_extension/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Liu-Yonghu/3DHighlighter.git"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TZlPTvm91dbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install required packages"
      ],
      "metadata": {
        "id": "x1u2hyhHCRyg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PigOw_d2E15i",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#!pip install ftfy regex tqdm\n",
        "!pip install open3d\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install kaolin==0.17.0 -f https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.5.1_cu121.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Runing on the voxel version"
      ],
      "metadata": {
        "id": "ru0qwzROlrWA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warp 1.6.2 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.6.2\n",
            "dict_keys(['shape_id', 'semantic_class', 'affordance', 'data_info', 'coordinates', 'labels'])\n",
            "Coordinates Shape: torch.Size([1, 2048, 3])\n",
            "/usr/local/lib/python3.11/dist-packages/kaolin/ops/conversions/pointcloud.py:66: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:644.)\n",
            "  vg = torch.sparse.FloatTensor(\n",
            "faces shape: torch.Size([16384, 3])\n",
            "face_normals shape: torch.Size([1, 16384, 3, 3])\n",
            "Mesh saved at: /content/drive/MyDrive/data/data_from_voxel/Chair.obj\n",
            "100%|████████████████████████████████████████| 890M/890M [00:08<00:00, 106MiB/s]\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=3, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (7): ReLU()\n",
            "  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (9): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (10): ReLU()\n",
            "  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (12): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (13): ReLU()\n",
            "  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (15): Linear(in_features=256, out_features=2, bias=True)\n",
            "  (16): Softmax(dim=1)\n",
            ")\n",
            "  0% 0/1000 [00:00<?, ?it/s]Last 100 CLIP score: -0.1551513671875\n",
            "  1% 14/1000 [00:05<06:14,  2.63it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/./3DHighlighter/main.py\", line 310, in <module>\n",
            "    optimize(args)\n",
            "  File \"/content/./3DHighlighter/main.py\", line 153, in optimize\n",
            "    loss.backward(retain_graph=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python ./3DHighlighter/main.py --seed 1 --n_iter 1000 --voxel True"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NllsZ4jGBJ9-",
        "outputId": "13d6f06e-0db2-4745-fc65-f434136d5eaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./3DHighlighter/main.py --seed 2 --n_iter 1000 --voxel True"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IwcgY2kblx9L",
        "outputId": "111a215a-b5bd-4262-e33f-90e43abe25f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warp 1.6.2 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.6.2\n",
            "dict_keys(['shape_id', 'semantic_class', 'affordance', 'data_info', 'coordinates', 'labels'])\n",
            "Coordinates Shape: torch.Size([1, 2048, 3])\n",
            "/usr/local/lib/python3.11/dist-packages/kaolin/ops/conversions/pointcloud.py:66: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:651.)\n",
            "  vg = torch.sparse.FloatTensor(\n",
            "faces shape: torch.Size([2544, 3])\n",
            "face_normals shape: torch.Size([1, 2544, 3, 3])\n",
            "Mesh saved at: /content/drive/MyDrive/data/data_from_voxel/Knife.obj\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=3, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (7): ReLU()\n",
            "  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (9): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (10): ReLU()\n",
            "  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (12): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (13): ReLU()\n",
            "  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (15): Linear(in_features=256, out_features=2, bias=True)\n",
            "  (16): Softmax(dim=1)\n",
            ")\n",
            "  0% 0/1000 [00:00<?, ?it/s]Last 100 CLIP score: -0.27099609375\n",
            " 10% 100/1000 [00:22<03:08,  4.78it/s]Last 100 CLIP score: -0.2690478515625\n",
            " 20% 200/1000 [00:43<02:48,  4.75it/s]Last 100 CLIP score: -0.26881103515625\n",
            " 30% 300/1000 [01:04<02:30,  4.65it/s]Last 100 CLIP score: -0.26573974609375\n",
            " 40% 400/1000 [01:26<02:07,  4.70it/s]Last 100 CLIP score: -0.26755859375\n",
            " 50% 500/1000 [01:47<01:49,  4.56it/s]Last 100 CLIP score: -0.2678857421875\n",
            " 60% 600/1000 [02:09<01:25,  4.67it/s]Last 100 CLIP score: -0.268157958984375\n",
            " 70% 700/1000 [02:30<01:05,  4.57it/s]Last 100 CLIP score: -0.26790283203125\n",
            " 80% 800/1000 [02:52<00:43,  4.62it/s]Last 100 CLIP score: -0.26629638671875\n",
            " 90% 900/1000 [03:14<00:22,  4.51it/s]Last 100 CLIP score: -0.267886962890625\n",
            "100% 1000/1000 [03:36<00:00,  4.63it/s]\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=3, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (7): ReLU()\n",
            "  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (9): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (10): ReLU()\n",
            "  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (12): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (13): ReLU()\n",
            "  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (15): Linear(in_features=256, out_features=2, bias=True)\n",
            "  (16): Softmax(dim=1)\n",
            ")\n",
            "  0% 0/1000 [00:00<?, ?it/s]Last 100 CLIP score: -0.279541015625\n",
            " 10% 100/1000 [00:21<03:17,  4.57it/s]Last 100 CLIP score: -0.280625\n",
            " 20% 200/1000 [00:43<02:52,  4.64it/s]Last 100 CLIP score: -0.2814111328125\n",
            " 30% 300/1000 [01:05<02:34,  4.54it/s]Last 100 CLIP score: -0.28040283203125\n",
            " 40% 400/1000 [01:26<02:09,  4.62it/s]Last 100 CLIP score: -0.28193115234375\n",
            " 50% 500/1000 [01:48<01:48,  4.62it/s]Last 100 CLIP score: -0.28212890625\n",
            " 60% 600/1000 [02:10<01:26,  4.63it/s]Last 100 CLIP score: -0.281302490234375\n",
            " 70% 700/1000 [02:32<01:04,  4.62it/s]Last 100 CLIP score: -0.2796435546875\n",
            " 80% 800/1000 [02:54<00:44,  4.53it/s]Last 100 CLIP score: -0.280316162109375\n",
            " 90% 900/1000 [03:16<00:21,  4.60it/s]Last 100 CLIP score: -0.28241943359375\n",
            "100% 1000/1000 [03:38<00:00,  4.59it/s]\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=3, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (7): ReLU()\n",
            "  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (9): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (10): ReLU()\n",
            "  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (12): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (13): ReLU()\n",
            "  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (15): Linear(in_features=256, out_features=2, bias=True)\n",
            "  (16): Softmax(dim=1)\n",
            ")\n",
            "  0% 0/1000 [00:00<?, ?it/s]Last 100 CLIP score: -0.293212890625\n",
            " 10% 100/1000 [00:21<03:12,  4.67it/s]Last 100 CLIP score: -0.2909228515625\n",
            " 20% 200/1000 [00:43<02:56,  4.55it/s]Last 100 CLIP score: -0.29290283203125\n",
            " 30% 300/1000 [01:05<02:32,  4.60it/s]Last 100 CLIP score: -0.28633056640625\n",
            " 40% 400/1000 [01:27<02:11,  4.56it/s]Last 100 CLIP score: -0.28585693359375\n",
            " 50% 500/1000 [01:48<01:48,  4.60it/s]Last 100 CLIP score: -0.28874267578125\n",
            " 60% 600/1000 [02:10<01:29,  4.47it/s]Last 100 CLIP score: -0.286527099609375\n",
            " 70% 700/1000 [02:32<01:05,  4.59it/s]Last 100 CLIP score: -0.28545654296875\n",
            " 80% 800/1000 [02:54<00:43,  4.60it/s]Last 100 CLIP score: -0.28568359375\n",
            " 90% 900/1000 [03:16<00:21,  4.57it/s]Last 100 CLIP score: -0.289481201171875\n",
            "100% 1000/1000 [03:38<00:00,  4.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./3DHighlighter/main.py --seed 3 --n_iter 1000 --voxel True"
      ],
      "metadata": {
        "id": "heufzsBZl0N_",
        "outputId": "c10f7dfc-24d8-4282-9cb3-b24b9fbbcba8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warp 1.6.2 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.6.2\n",
            "dict_keys(['shape_id', 'semantic_class', 'affordance', 'data_info', 'coordinates', 'labels'])\n",
            "Coordinates Shape: torch.Size([1, 2048, 3])\n",
            "/usr/local/lib/python3.11/dist-packages/kaolin/ops/conversions/pointcloud.py:66: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:651.)\n",
            "  vg = torch.sparse.FloatTensor(\n",
            "faces shape: torch.Size([21176, 3])\n",
            "face_normals shape: torch.Size([1, 21176, 3, 3])\n",
            "Mesh saved at: /content/drive/MyDrive/data/data_from_voxel/Chair.obj\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=3, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (7): ReLU()\n",
            "  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (9): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (10): ReLU()\n",
            "  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (12): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (13): ReLU()\n",
            "  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (15): Linear(in_features=256, out_features=2, bias=True)\n",
            "  (16): Softmax(dim=1)\n",
            ")\n",
            "  0% 0/1000 [00:00<?, ?it/s]Last 100 CLIP score: -0.222900390625\n",
            " 10% 100/1000 [00:27<04:11,  3.58it/s]Last 100 CLIP score: -0.232103271484375\n",
            " 20% 200/1000 [00:55<03:44,  3.56it/s]Last 100 CLIP score: -0.233861083984375\n",
            " 30% 300/1000 [01:23<03:17,  3.54it/s]Last 100 CLIP score: -0.23317626953125\n",
            " 40% 400/1000 [01:51<02:50,  3.53it/s]Last 100 CLIP score: -0.232230224609375\n",
            " 50% 500/1000 [02:19<02:22,  3.50it/s]Last 100 CLIP score: -0.230771484375\n",
            " 60% 600/1000 [02:47<01:53,  3.51it/s]Last 100 CLIP score: -0.229609375\n",
            " 70% 700/1000 [03:15<01:25,  3.51it/s]Last 100 CLIP score: -0.2294677734375\n",
            " 80% 800/1000 [03:43<00:56,  3.52it/s]Last 100 CLIP score: -0.228778076171875\n",
            " 90% 900/1000 [04:12<00:28,  3.51it/s]Last 100 CLIP score: -0.2307763671875\n",
            "100% 1000/1000 [04:40<00:00,  3.56it/s]\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=3, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (7): ReLU()\n",
            "  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (9): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (10): ReLU()\n",
            "  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (12): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (13): ReLU()\n",
            "  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (15): Linear(in_features=256, out_features=2, bias=True)\n",
            "  (16): Softmax(dim=1)\n",
            ")\n",
            "  0% 0/1000 [00:00<?, ?it/s]Last 100 CLIP score: -0.2232666015625\n",
            " 10% 100/1000 [00:28<04:11,  3.58it/s]Last 100 CLIP score: -0.236722412109375\n",
            " 20% 200/1000 [00:56<03:45,  3.54it/s]Last 100 CLIP score: -0.23965576171875\n",
            " 30% 300/1000 [01:24<03:17,  3.55it/s]Last 100 CLIP score: -0.230216064453125\n",
            " 40% 400/1000 [01:52<02:49,  3.55it/s]Last 100 CLIP score: -0.23739990234375\n",
            " 50% 500/1000 [02:21<02:21,  3.54it/s]Last 100 CLIP score: -0.2316064453125\n",
            " 60% 600/1000 [02:49<01:52,  3.54it/s]Last 100 CLIP score: -0.23843505859375\n",
            " 70% 700/1000 [03:17<01:24,  3.53it/s]Last 100 CLIP score: -0.23872802734375\n",
            " 80% 800/1000 [03:46<00:56,  3.53it/s]Last 100 CLIP score: -0.2303125\n",
            " 90% 900/1000 [04:14<00:28,  3.53it/s]Last 100 CLIP score: -0.2342529296875\n",
            "100% 1000/1000 [04:42<00:00,  3.54it/s]\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=3, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (7): ReLU()\n",
            "  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (9): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (10): ReLU()\n",
            "  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (12): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (13): ReLU()\n",
            "  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (15): Linear(in_features=256, out_features=2, bias=True)\n",
            "  (16): Softmax(dim=1)\n",
            ")\n",
            "  0% 0/1000 [00:00<?, ?it/s]Last 100 CLIP score: -0.2222900390625\n",
            " 10% 100/1000 [00:28<04:12,  3.56it/s]Last 100 CLIP score: -0.22711669921875\n",
            " 20% 200/1000 [00:56<03:45,  3.55it/s]Last 100 CLIP score: -0.233624267578125\n",
            " 30% 300/1000 [01:24<03:16,  3.56it/s]Last 100 CLIP score: -0.2265478515625\n",
            " 40% 400/1000 [01:53<02:49,  3.54it/s]Last 100 CLIP score: -0.2271484375\n",
            " 50% 500/1000 [02:21<02:21,  3.53it/s]Last 100 CLIP score: -0.231639404296875\n",
            " 60% 600/1000 [02:49<01:52,  3.55it/s]Last 100 CLIP score: -0.23205322265625\n",
            " 70% 700/1000 [03:18<01:24,  3.54it/s]Last 100 CLIP score: -0.22807861328125\n",
            " 80% 800/1000 [03:46<00:56,  3.53it/s]Last 100 CLIP score: -0.228690185546875\n",
            " 90% 900/1000 [04:15<00:28,  3.52it/s]Last 100 CLIP score: -0.230911865234375\n",
            "100% 1000/1000 [04:43<00:00,  3.53it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./3DHighlighter/main.py --seed 0 --n_iter 100 --voxel True"
      ],
      "metadata": {
        "id": "HpDwR7LB4i0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r voxel_results.zip ./voxel_results\n",
        "files.download(\"./voxel_results.zip\")"
      ],
      "metadata": {
        "id": "0monxCxzDY4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2DpY1QfUvI4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running on the approximate mesh"
      ],
      "metadata": {
        "id": "B5o2NI-yvL7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./3DHighlighter/main.py --seed 0 --n_iter 1000 --appro_mesh True"
      ],
      "metadata": {
        "id": "EkMw_mJ5vVnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./3DHighlighter/main.py --seed 19 --n_iter 1000 --appro_mesh True"
      ],
      "metadata": {
        "id": "CzYL3kkAfyIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./3DHighlighter/main.py --seed 2 --n_iter 1000 --appro_mesh True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKGM3jXVfyny",
        "outputId": "598f5cc5-e6b3-4d0c-b813-a573a6dcbaad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warp 1.6.2 initialized:\n",
            "   CUDA Toolkit 12.8, Driver 12.4\n",
            "   Devices:\n",
            "     \"cpu\"      : \"x86_64\"\n",
            "     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n",
            "   Kernel cache:\n",
            "     /root/.cache/warp/1.6.2\n",
            "dict_keys(['shape_id', 'semantic_class', 'affordance', 'data_info', 'coordinates', 'labels'])\n",
            "Coordinates Shape: torch.Size([2048, 3])\n",
            "\u001b[1;33m[Open3D WARNING] Write OBJ can not include triangle normals.\u001b[0;m\n",
            "Mesh saved at: data_extension/data_from_appro/Knife.obj\n",
            "A 3D render of knife with a highlighted handle for grasping\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=3, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (7): ReLU()\n",
            "  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (9): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (10): ReLU()\n",
            "  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (12): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (13): ReLU()\n",
            "  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (15): Linear(in_features=256, out_features=2, bias=True)\n",
            "  (16): Softmax(dim=1)\n",
            ")\n",
            "  0% 0/1000 [00:00<?, ?it/s]Last 100 CLIP score: -0.283447265625\n",
            " 10% 100/1000 [00:21<03:08,  4.78it/s]Last 100 CLIP score: -0.27993408203125\n",
            " 20% 200/1000 [00:42<02:53,  4.62it/s]Last 100 CLIP score: -0.279908447265625\n",
            " 30% 300/1000 [01:04<02:35,  4.49it/s]Last 100 CLIP score: -0.279388427734375\n",
            " 40% 400/1000 [01:27<02:19,  4.29it/s]Last 100 CLIP score: -0.2774609375\n",
            " 50% 500/1000 [01:51<01:57,  4.25it/s]Last 100 CLIP score: -0.278233642578125\n",
            " 60% 600/1000 [02:14<01:30,  4.41it/s]Last 100 CLIP score: -0.2790478515625\n",
            " 70% 700/1000 [02:37<01:07,  4.45it/s]Last 100 CLIP score: -0.2782666015625\n",
            " 80% 800/1000 [02:59<00:46,  4.29it/s]Last 100 CLIP score: -0.276337890625\n",
            " 90% 900/1000 [03:23<00:22,  4.37it/s]Last 100 CLIP score: -0.2798974609375\n",
            " 95% 949/1000 [03:34<00:11,  4.38it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./3DHighlighter/main.py --seed 5 --n_iter 100 --appro_mesh True"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ODmj6xnHf0il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#This is the demo of running the project"
      ],
      "metadata": {
        "id": "CY9YBS9uASnx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lOg6_DwGbb9"
      },
      "outputs": [],
      "source": [
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle --seed 0 --classes hat --object candle --n_iter 100 --frontview_center 3.14 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# !!!this command depends on the practice to run"
      ],
      "metadata": {
        "id": "Pus0peAOEphU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r ./3DHighlighter/results/demo_candle"
      ],
      "metadata": {
        "id": "Z92p8wzbDtf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r ./results/"
      ],
      "metadata": {
        "id": "mIoDqMXQD1eK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Grid serach"
      ],
      "metadata": {
        "id": "4AD8MfjiAfUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##dog"
      ],
      "metadata": {
        "id": "zDSJ-OSRHA5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/dog.obj --output_dir results/demo_dog/base --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 4 --n_views 5 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/dog.obj --output_dir results/demo_dog/EXP1 --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0005 --depth 4 --n_views 5 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/dog.obj --output_dir results/demo_dog/EXP2 --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.00001 --depth 4 --n_views 5 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/dog.obj --output_dir results/demo_dog/EXP3 --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 3 --n_views 5 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/dog.obj --output_dir results/demo_dog/EXP4 --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 6 --n_views 5 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/dog.obj --output_dir results/demo_dog/EXP5 --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 4 --n_views 3 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/dog.obj --output_dir results/demo_dog/EXP6 --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 4 --n_views 10 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/dog.obj --output_dir results/demo_dog/EXP7 --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 4 --n_views 5 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/dog.obj --output_dir results/demo_dog/EXP8 --seed 0 --classes shoes --object dog --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0005 --depth 6 --n_views 10 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/dog.obj --output_dir results/demo_dog/EXP9 --seed 0 --classes shoes --object dog --n_iter 1000 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 4 --n_views 5 --n_augs 3\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/dog.obj --output_dir results/demo_dog/EXP10 --seed 0 --classes shoes --object dog --n_iter 1000 --frontview_center 3.14 0 --learning_rate 0.0005 --depth 6 --n_views 10 --n_augs 3"
      ],
      "metadata": {
        "id": "dNFg-4VbKbkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##candle"
      ],
      "metadata": {
        "id": "wDOHEfEfN43R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/base --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 4 --n_views 5 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/EXP1 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0005 --depth 4 --n_views 5 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/EXP2 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.00001 --depth 4 --n_views 5 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/EXP3 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 3 --n_views 5 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/EXP4 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 6 --n_views 5 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/EXP5 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 4 --n_views 3 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/EXP6 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 4 --n_views 10 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/EXP7 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 4 --n_views 5 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/EXP8 --seed 0 --classes hat --object candle --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0005 --depth 6 --n_views 10 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/EXP9 --seed 0 --classes hat --object candle --n_iter 1000 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 4 --n_views 5 --n_augs 3\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/candle.obj --output_dir results/demo_candle/EXP10 --seed 0 --classes hat --object candle --n_iter 1000 --frontview_center 3.14 0 --learning_rate 0.0005 --depth 6 --n_views 10 --n_augs 3\n"
      ],
      "metadata": {
        "id": "wCtvpSHWNu9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##horse"
      ],
      "metadata": {
        "id": "gUPQnbWPN8Vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/base --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 4 --n_views 5 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/EXP1 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0005 --depth 4 --n_views 5 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/EXP2 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.00001 --depth 4 --n_views 5 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/EXP3 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 3 --n_views 5 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/EXP4 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 6 --n_views 5 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/EXP5 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 4 --n_views 3 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/EXP6 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 4 --n_views 10 --n_augs 1\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/EXP7 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 4 --n_views 5 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/EXP8 --seed 0 --classes necklace --object horse --n_iter 2500 --frontview_center 3.14 0 --learning_rate 0.0005 --depth 6 --n_views 10 --n_augs 2\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/EXP9 --seed 0 --classes necklace --object horse --n_iter 1000 --frontview_center 3.14 0 --learning_rate 0.0001 --depth 4 --n_views 5 --n_augs 3\n",
        "!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse/EXP10 --seed 0 --classes necklace --object horse --n_iter 1000 --frontview_center 3.14 0 --learning_rate 0.0005 --depth 6 --n_views 10 --n_augs 3"
      ],
      "metadata": {
        "id": "i-1qSQf1N_AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Automated search the hyperparameter"
      ],
      "metadata": {
        "id": "AKCuDwedAj0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!python ./3DHighlighter/main.py --obj_path ./3DHighlighter/data/horse.obj --output_dir results/demo_horse --seed 0 --classes horse --object horse --n_iter 1000 --frontview_center 3.14 0"
      ],
      "metadata": {
        "id": "rxcZMx4ehUKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#save the result"
      ],
      "metadata": {
        "id": "PQCvg_haQQ9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r results.zip ./results"
      ],
      "metadata": {
        "id": "wDgUQ55GSR-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/drive/MyDrive/3DHighlighter/results/"
      ],
      "metadata": {
        "id": "gqHycttNS8OO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "Pus0peAOEphU"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}